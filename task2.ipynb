{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a37c75dd",
   "metadata": {},
   "source": [
    "## Task 2.2: Mining Cancer Feature Patterns\n",
    "\n",
    "**Dataset:**  \n",
    "Breast Cancer Wisconsin (Diagnostic)\n",
    "\n",
    "**Source:**  \n",
    "`sklearn.datasets.load_breast_cancer()` — mirrors the UCI Wisconsin dataset.(Wolberg et al., UCI Machine Learning Repository).\n",
    "\n",
    "**Goal:**  \n",
    "Derive **ordered feature sequences per patient** and **mine frequent sequential patterns** to uncover relationships and progression trends among diagnostic features.\n",
    "\n",
    "**External tools used in this notebook:**\n",
    "   - scikit-learn: data loading, preprocessing, discretization\n",
    "   - PrefixSpan (Pei et al. 2001): sequential pattern mining algorithm (we use a Python implementation from the open-source `prefixspan` package: pip install prefixspan)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4369dd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import KBinsDiscretizer, StandardScaler\n",
    "\n",
    "# We will use PrefixSpan for sequential pattern mining.\n",
    "# Reference:\n",
    "# Pei, J., Han, J., Mortazavi-Asl, B., Pinto, H., Chen, Q., Dayal, U., & Hsu, M. (2001).\n",
    "# PrefixSpan: Mining Sequential Patterns Efficiently by Prefix-Projected Pattern Growth.\n",
    "# Note: We'll use a Python implementation available as the `prefixspan` package.\n",
    "try:\n",
    "    from prefixspan import PrefixSpan\n",
    "except ImportError:\n",
    "    print(\"Please install prefixspan first: pip install prefixspan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbf47eb",
   "metadata": {},
   "source": [
    "### 1. Load and Inspect Data\n",
    "We loaded the Breast Cancer Wisconsin dataset using sklearn.datasets.load_breast_cancer() and attached diagnosis labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9639de4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0        17.99         10.38          122.80     1001.0          0.11840   \n",
      "1        20.57         17.77          132.90     1326.0          0.08474   \n",
      "2        19.69         21.25          130.00     1203.0          0.10960   \n",
      "3        11.42         20.38           77.58      386.1          0.14250   \n",
      "4        20.29         14.34          135.10     1297.0          0.10030   \n",
      "\n",
      "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0           0.27760          0.3001              0.14710         0.2419   \n",
      "1           0.07864          0.0869              0.07017         0.1812   \n",
      "2           0.15990          0.1974              0.12790         0.2069   \n",
      "3           0.28390          0.2414              0.10520         0.2597   \n",
      "4           0.13280          0.1980              0.10430         0.1809   \n",
      "\n",
      "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
      "0                 0.07871  ...          17.33           184.60      2019.0   \n",
      "1                 0.05667  ...          23.41           158.80      1956.0   \n",
      "2                 0.05999  ...          25.53           152.50      1709.0   \n",
      "3                 0.09744  ...          26.50            98.87       567.7   \n",
      "4                 0.05883  ...          16.67           152.20      1575.0   \n",
      "\n",
      "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
      "0            0.1622             0.6656           0.7119                0.2654   \n",
      "1            0.1238             0.1866           0.2416                0.1860   \n",
      "2            0.1444             0.4245           0.4504                0.2430   \n",
      "3            0.2098             0.8663           0.6869                0.2575   \n",
      "4            0.1374             0.2050           0.4000                0.1625   \n",
      "\n",
      "   worst symmetry  worst fractal dimension  diagnosis  \n",
      "0          0.4601                  0.11890          M  \n",
      "1          0.2750                  0.08902          M  \n",
      "2          0.3613                  0.08758          M  \n",
      "3          0.6638                  0.17300          M  \n",
      "4          0.2364                  0.07678          M  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "(569, 31)\n",
      "diagnosis\n",
      "B    357\n",
      "M    212\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)  # 30 numeric features\n",
    "y = pd.Series(data.target)  # binary target: 0=malignant, 1=benign\n",
    "\n",
    "# In sklearn breast_cancer:\n",
    "# target 0 = malignant, 1 = benign\n",
    "# Let's map to strings 'M'/'B' like the Kaggle/real dataset format\n",
    "diagnosis_map = {0: \"M\", 1: \"B\"}\n",
    "diagnosis = y.map(diagnosis_map)\n",
    "\n",
    "df = X.copy()\n",
    "df[\"diagnosis\"] = diagnosis\n",
    "\n",
    "print(df.head())\n",
    "print(df.shape)\n",
    "print(df[\"diagnosis\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e81c37",
   "metadata": {},
   "source": [
    "### 2. Scale and Discretize Features\n",
    "\n",
    "#### Why scale?\n",
    "\n",
    "We standardize z-score each feature so we can later ask: “For this patient, which features are most abnormal compared to the full population?”\n",
    "\n",
    "The Z-score is defined as:\n",
    "\n",
    "$$\n",
    "z = \\frac{x - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $x$: the feature value for a specific patient  \n",
    "- $\\mu$: the mean of that feature across the population  \n",
    "- $\\sigma$: the standard deviation of that feature across the population  \n",
    "\n",
    "\n",
    "#### Why discretize?\n",
    "\n",
    "We need to turn continuous features like `radius`, `texture`, and `concavity` into categories like  \n",
    "`low`, `mid`, `high`, using `KBinsDiscretizer` with strategies such as:\n",
    "\n",
    "- `uniform`\n",
    "- `quantile`\n",
    "- `kmeans`\n",
    "\n",
    "We'll start with one (like `quantile`) for mining, and show `sensitivity` later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c884bfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top features by mutual information with diagnosis (higher = more predictive):\n",
      "worst perimeter         0.471842\n",
      "worst area              0.464313\n",
      "worst radius            0.451230\n",
      "mean concave points     0.438806\n",
      "worst concave points    0.436255\n",
      "mean perimeter          0.402361\n",
      "mean concavity          0.375447\n",
      "mean radius             0.362276\n",
      "mean area               0.360023\n",
      "area error              0.340759\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# We standardize features using z-scores:\n",
    "# This lets us rank \"how extreme\" each feature is for a given patient.\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns, index=X.index)\n",
    "\n",
    "# We can also measure how predictive each feature is of diagnosis\n",
    "# using mutual information (MI). MI is a non-linear dependency measure.\n",
    "# This uses scikit-learn's mutual_info_classif.\n",
    "mi_scores = mutual_info_classif(X, y, discrete_features=False, random_state=42)\n",
    "mi_series = pd.Series(mi_scores, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "print(\"Top features by mutual information with diagnosis (higher = more predictive):\")\n",
    "print(mi_series.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2eccc0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinqingyang/opt/anaconda3/envs/sc4020/lib/python3.10/site-packages/sklearn/preprocessing/_discretization.py:296: FutureWarning: The current default behavior, quantile_method='linear', will be changed to quantile_method='averaged_inverted_cdf' in scikit-learn version 1.9 to naturally support sample weight equivalence properties by default. Pass quantile_method='averaged_inverted_cdf' explicitly to silence this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample rows - uniform binning:\n",
      "  mean radius mean texture mean perimeter mean area mean smoothness  \\\n",
      "0         mid          low            mid       mid             mid   \n",
      "1         mid          low            mid       mid             low   \n",
      "2         mid          mid            mid       mid             mid   \n",
      "\n",
      "  mean compactness mean concavity mean concave points mean symmetry  \\\n",
      "0             high           high                high          high   \n",
      "1              low            low                 mid           mid   \n",
      "2              mid            mid                 mid           mid   \n",
      "\n",
      "  mean fractal dimension  ... worst radius worst texture worst perimeter  \\\n",
      "0                    mid  ...          mid           low            high   \n",
      "1                    low  ...          mid           low             mid   \n",
      "2                    low  ...          mid           mid             mid   \n",
      "\n",
      "  worst area worst smoothness worst compactness worst concavity  \\\n",
      "0        mid              mid               mid             mid   \n",
      "1        mid              mid               low             low   \n",
      "2        mid              mid               mid             mid   \n",
      "\n",
      "  worst concave points worst symmetry worst fractal dimension  \n",
      "0                 high            mid                     mid  \n",
      "1                  mid            low                     low  \n",
      "2                 high            mid                     low  \n",
      "\n",
      "[3 rows x 30 columns]\n",
      "\n",
      "Sample rows - quantile binning:\n",
      "  mean radius mean texture mean perimeter mean area mean smoothness  \\\n",
      "0        high          low           high      high            high   \n",
      "1        high          mid           high      high             low   \n",
      "2        high         high           high      high            high   \n",
      "\n",
      "  mean compactness mean concavity mean concave points mean symmetry  \\\n",
      "0             high           high                high          high   \n",
      "1              mid            mid                high           mid   \n",
      "2             high           high                high          high   \n",
      "\n",
      "  mean fractal dimension  ... worst radius worst texture worst perimeter  \\\n",
      "0                   high  ...         high           low            high   \n",
      "1                    low  ...         high           mid            high   \n",
      "2                    mid  ...         high           mid            high   \n",
      "\n",
      "  worst area worst smoothness worst compactness worst concavity  \\\n",
      "0       high             high              high            high   \n",
      "1       high              mid               mid             mid   \n",
      "2       high             high              high            high   \n",
      "\n",
      "  worst concave points worst symmetry worst fractal dimension  \n",
      "0                 high           high                    high  \n",
      "1                 high            mid                    high  \n",
      "2                 high           high                    high  \n",
      "\n",
      "[3 rows x 30 columns]\n",
      "\n",
      "Sample rows - kmeans binning:\n",
      "  mean radius mean texture mean perimeter mean area mean smoothness  \\\n",
      "0        high          low           high       mid            high   \n",
      "1        high          mid           high       mid             low   \n",
      "2        high          mid           high       mid            high   \n",
      "\n",
      "  mean compactness mean concavity mean concave points mean symmetry  \\\n",
      "0             high           high                high          high   \n",
      "1              low            mid                 mid           mid   \n",
      "2              mid            mid                high           mid   \n",
      "\n",
      "  mean fractal dimension  ... worst radius worst texture worst perimeter  \\\n",
      "0                   high  ...         high           low            high   \n",
      "1                    low  ...         high           mid            high   \n",
      "2                    low  ...         high           mid            high   \n",
      "\n",
      "  worst area worst smoothness worst compactness worst concavity  \\\n",
      "0        mid             high              high            high   \n",
      "1        mid              low               low             mid   \n",
      "2        mid              mid               mid             mid   \n",
      "\n",
      "  worst concave points worst symmetry worst fractal dimension  \n",
      "0                 high           high                    high  \n",
      "1                 high            low                     mid  \n",
      "2                 high            mid                     mid  \n",
      "\n",
      "[3 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# We convert each continuous feature column into categorical bins:\n",
    "#   'low', 'mid', 'high'\n",
    "# Using scikit-learn's KBinsDiscretizer.\n",
    "# We will mainly use 'quantile' for mining, but we also generate 'uniform' and\n",
    "# 'kmeans' for a sensitivity analysis later, as required by the task.\n",
    "\n",
    "\n",
    "def discretize_features(X_in, strategy, n_bins=3):\n",
    "    \"\"\"\n",
    "    Discretize continuous features using KBinsDiscretizer.\n",
    "    strategy: 'uniform', 'quantile', or 'kmeans'\n",
    "    Returns a dataframe of same shape but with categorical labels: 'low','mid','high'\n",
    "    \"\"\"\n",
    "    kbd = KBinsDiscretizer(n_bins=n_bins, encode=\"ordinal\", strategy=strategy)\n",
    "    binned = kbd.fit_transform(X_in)\n",
    "\n",
    "    # map 0->low, 1->mid, 2->high (generalizable to n_bins, but report expects 3 bins)\n",
    "    bin_labels = dict(enumerate([\"low\", \"mid\", \"high\"][:n_bins]))\n",
    "\n",
    "    df_cat = pd.DataFrame(binned, columns=X_in.columns, index=X_in.index)\n",
    "    for col in df_cat.columns:\n",
    "        df_cat[col] = df_cat[col].map(bin_labels)\n",
    "\n",
    "    return df_cat\n",
    "\n",
    "\n",
    "disc_uniform = discretize_features(X, strategy=\"uniform\", n_bins=3)\n",
    "disc_quantile = discretize_features(X, strategy=\"quantile\", n_bins=3)\n",
    "disc_kmeans = discretize_features(X, strategy=\"kmeans\", n_bins=3)\n",
    "\n",
    "print(\"Sample rows - uniform binning:\")\n",
    "print(disc_uniform.head(3))\n",
    "\n",
    "print(\"\\nSample rows - quantile binning:\")\n",
    "print(disc_quantile.head(3))\n",
    "\n",
    "print(\"\\nSample rows - kmeans binning:\")\n",
    "print(disc_kmeans.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc3beeb",
   "metadata": {},
   "source": [
    "### 3. Rank Features Per Patient and Build Sequences\n",
    "We turned each row (patient) into an ordered sequence.\n",
    "\n",
    "**For a given patient (row index = `idx`):**\n",
    "\n",
    "1. Look at their z-scores for all features.  \n",
    "2. Rank features by absolute z-score (|z|) in descending order → identifies which features are most abnormal for **this patient**.  \n",
    "3. Select the top k features.  \n",
    "4. Handle ties: features with the same |z| within `tie_eps` are grouped into the same itemset.  \n",
    "5. Convert each feature into a symbolic token in the format:  \n",
    "   `feature_name=low/mid/high`,  \n",
    "   using the discretized DataFrame (`disc_df`).\n",
    "\n",
    "---\n",
    "\n",
    "**Output format (nested itemsets):**\n",
    "```python\n",
    "[\n",
    "    ['worst_concavity=high', 'worst_compactness=high'],   # most abnormal tie\n",
    "    ['radius_mean=high'],\n",
    "    ['smoothness_mean=low']\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf3e7cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 0, diagnosis=M\n",
      "[['mean compactness=high'], ['perimeter error=high'], ['worst symmetry=high'], ['mean concavity=high'], ['worst compactness=high']]\n",
      "\n",
      "Patient 1, diagnosis=M\n",
      "[['mean area=high'], ['worst area=high'], ['mean radius=high'], ['worst radius=high'], ['mean perimeter=high']]\n",
      "\n",
      "Patient 2, diagnosis=M\n",
      "[['mean concave points=high'], ['worst concave points=high'], ['mean radius=high'], ['mean perimeter=high'], ['mean area=high']]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def build_patient_sequence(idx, X_scaled_df, disc_df, k=5, tie_eps=1e-6):\n",
    "    \"\"\"\n",
    "    Returns a sequence (list of itemsets), where each itemset is a list of strings.\n",
    "    Example: [ ['radius_mean=high'], ['texture_mean=high', 'area_mean=high'], ... ]\n",
    "    \"\"\"\n",
    "    # 1. z-scores for this patient\n",
    "    z_row = X_scaled_df.loc[idx]\n",
    "\n",
    "    # 2. sort features by absolute deviation\n",
    "    #    we'll keep (feature, abs_z, signed_z)\n",
    "    feat_stats = []\n",
    "    for feat in X_scaled_df.columns:\n",
    "        feat_stats.append((feat, abs(z_row[feat]), z_row[feat]))\n",
    "    feat_stats.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # 3. take top-k\n",
    "    top_feats = feat_stats[:k]\n",
    "\n",
    "    # 4. group ties by abs_z within tie_eps to form itemsets\n",
    "    sequence = []\n",
    "    current_bucket = [top_feats[0]]\n",
    "    for fstat in top_feats[1:]:\n",
    "        if abs(fstat[1] - current_bucket[-1][1]) <= tie_eps:\n",
    "            current_bucket.append(fstat)\n",
    "        else:\n",
    "            sequence.append(current_bucket)\n",
    "            current_bucket = [fstat]\n",
    "    sequence.append(current_bucket)\n",
    "\n",
    "    # 5. convert buckets to itemsets of \"feature=level\"\n",
    "    #    get discretized level from disc_df\n",
    "    seq_itemsets = []\n",
    "    for bucket in sequence:\n",
    "        itemset = []\n",
    "        for feat, _, _ in bucket:\n",
    "            level = disc_df.loc[idx, feat]  # 'low'/'mid'/'high'\n",
    "            itemset.append(f\"{feat}={level}\")\n",
    "        seq_itemsets.append(itemset)\n",
    "\n",
    "    return seq_itemsets\n",
    "\n",
    "\n",
    "# We'll build sequences for all patients using quantile discretization\n",
    "# (the one we'll mine first)\n",
    "seqs_all = []\n",
    "labels_all = []\n",
    "for idx in X.index:\n",
    "    seq = build_patient_sequence(idx, X_scaled_df, disc_quantile, k=5, tie_eps=1e-6)\n",
    "    seqs_all.append(seq)\n",
    "    labels_all.append(diagnosis.loc[idx])\n",
    "\n",
    "# Sanity check a couple sequences\n",
    "for i in range(3):\n",
    "    print(f\"Patient {i}, diagnosis={labels_all[i]}\")\n",
    "    print(seqs_all[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bc68e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_item(item):\n",
    "    return item.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "\n",
    "\n",
    "seqs_all_clean = []\n",
    "for seq in seqs_all:\n",
    "    clean_seq = []\n",
    "    for itemset in seq:\n",
    "        clean_itemset = [sanitize_item(x) for x in itemset]\n",
    "        clean_seq.append(clean_itemset)\n",
    "    seqs_all_clean.append(clean_seq)\n",
    "\n",
    "# overwrite the original with the clean version for mining\n",
    "seqs_all = seqs_all_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fab723a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number malignant sequences: 212\n",
      "Number benign sequences: 357\n"
     ]
    }
   ],
   "source": [
    "seqs_M = [s for s, lab in zip(seqs_all, labels_all, strict=False) if lab == \"M\"]\n",
    "seqs_B = [s for s, lab in zip(seqs_all, labels_all, strict=False) if lab == \"B\"]\n",
    "\n",
    "print(\"Number malignant sequences:\", len(seqs_M))\n",
    "print(\"Number benign sequences:\", len(seqs_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f3b393",
   "metadata": {},
   "source": [
    "### 4. Preparing data for `prefixspan`\n",
    "\n",
    "The `prefixspan` library expects:\n",
    "\n",
    "- A list of **sequences**  \n",
    "- Each sequence to be a list of **hashable items** (e.g., strings)  \n",
    "- **No nested lists** inside lists\n",
    "\n",
    "---\n",
    "\n",
    "However, our current data structure contains **nested lists** (itemsets).  \n",
    "We'll “compress” each itemset into a single string by **joining the items with `|`**.\n",
    "\n",
    "---\n",
    "\n",
    "**Example:**\n",
    "\n",
    "```python\n",
    "[['worst_concavity=high', 'worst_compactness=high'], ['radius_mean=high']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f67b647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After collapsing:\n",
      "Type of seqs_M_collapsed[0]: <class 'list'>\n",
      "seqs_M_collapsed[0]: ['mean_compactness=high', 'perimeter_error=high', 'worst_symmetry=high', 'mean_concavity=high', 'worst_compactness=high']\n",
      "Type of seqs_M_collapsed[0][0]: <class 'str'>\n",
      "seqs_M_collapsed[0][0]: mean_compactness=high\n"
     ]
    }
   ],
   "source": [
    "def collapse_itemsets_for_prefixspan(seq_with_itemsets):\n",
    "    \"\"\"\n",
    "    Input example for ONE patient:\n",
    "      [\n",
    "        ['feat1=high', 'feat2=high'],\n",
    "        ['feat3=low'],\n",
    "        ...\n",
    "      ]\n",
    "\n",
    "    Output we want:\n",
    "      [\n",
    "        'feat1=high|feat2=high',\n",
    "        'feat3=low',\n",
    "        ...\n",
    "      ]\n",
    "    \"\"\"\n",
    "    collapsed = []\n",
    "    for itemset in seq_with_itemsets:\n",
    "        # itemset is a list like ['feat1=high', 'feat2=high']\n",
    "        joined = \"|\".join(sorted(itemset))\n",
    "        collapsed.append(joined)\n",
    "    return collapsed\n",
    "\n",
    "\n",
    "# build NEW collapsed versions from your current seqs_M / seqs_B\n",
    "seqs_M_collapsed = [collapse_itemsets_for_prefixspan(s) for s in seqs_M]\n",
    "seqs_B_collapsed = [collapse_itemsets_for_prefixspan(s) for s in seqs_B]\n",
    "\n",
    "print(\"After collapsing:\")\n",
    "print(\"Type of seqs_M_collapsed[0]:\", type(seqs_M_collapsed[0]))\n",
    "print(\"seqs_M_collapsed[0]:\", seqs_M_collapsed[0])\n",
    "print(\"Type of seqs_M_collapsed[0][0]:\", type(seqs_M_collapsed[0][0]))\n",
    "print(\"seqs_M_collapsed[0][0]:\", seqs_M_collapsed[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07257d9",
   "metadata": {},
   "source": [
    "### 5a. Mine Sequential Patterns with PrefixSpan\n",
    "\n",
    "We now run **PrefixSpan** on:\n",
    "\n",
    "- **Malignant sequences only**\n",
    "- **Benign sequences only**\n",
    "\n",
    "We discover patterns like:\n",
    "\n",
    "**Citation Notes**\n",
    "\n",
    "PrefixSpan is an algorithm introduced in:\n",
    "Pei, J., Han, J., Mortazavi-Asl, B., Pinto, H., Chen, Q., Dayal, U., & Hsu, M. (2001).\n",
    "PrefixSpan: Mining Sequential Patterns Efficiently by Prefix-Projected Pattern Growth.\n",
    "\n",
    "We are using the open-source Python package prefixspan that implements this algorithm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea281547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top malignant patterns:\n",
      "support=60 / 212 (0.28)  pattern=['mean_radius=high']\n",
      "support=49 / 212 (0.23)  pattern=['worst_radius=high']\n",
      "support=47 / 212 (0.22)  pattern=['mean_area=high']\n",
      "support=45 / 212 (0.21)  pattern=['worst_compactness=high']\n",
      "support=43 / 212 (0.20)  pattern=['mean_perimeter=high']\n",
      "support=42 / 212 (0.20)  pattern=['worst_fractal_dimension=high']\n",
      "support=41 / 212 (0.19)  pattern=['worst_texture=high']\n",
      "support=40 / 212 (0.19)  pattern=['worst_perimeter=high']\n",
      "support=39 / 212 (0.18)  pattern=['mean_concave_points=high']\n",
      "support=39 / 212 (0.18)  pattern=['worst_concavity=high']\n",
      "support=38 / 212 (0.18)  pattern=['worst_symmetry=high']\n",
      "support=38 / 212 (0.18)  pattern=['worst_area=high']\n",
      "support=37 / 212 (0.17)  pattern=['radius_error=high']\n",
      "support=36 / 212 (0.17)  pattern=['worst_concave_points=high']\n",
      "support=35 / 212 (0.17)  pattern=['mean_concavity=high']\n",
      "support=35 / 212 (0.17)  pattern=['worst_smoothness=high']\n",
      "support=31 / 212 (0.15)  pattern=['perimeter_error=high']\n",
      "support=31 / 212 (0.15)  pattern=['mean_texture=high']\n",
      "support=30 / 212 (0.14)  pattern=['mean_radius=high', 'mean_perimeter=high']\n",
      "support=29 / 212 (0.14)  pattern=['mean_fractal_dimension=low']\n",
      "\n",
      "Top benign patterns:\n",
      "support=91 / 357 (0.25)  pattern=['worst_texture=low']\n",
      "support=84 / 357 (0.24)  pattern=['mean_texture=low']\n",
      "support=84 / 357 (0.24)  pattern=['worst_smoothness=low']\n",
      "support=81 / 357 (0.23)  pattern=['mean_smoothness=low']\n",
      "support=78 / 357 (0.22)  pattern=['mean_symmetry=low']\n",
      "support=73 / 357 (0.20)  pattern=['worst_concave_points=low']\n",
      "support=68 / 357 (0.19)  pattern=['concave_points_error=low']\n",
      "support=66 / 357 (0.18)  pattern=['texture_error=low']\n",
      "support=60 / 357 (0.17)  pattern=['mean_radius=low']\n",
      "support=58 / 357 (0.16)  pattern=['mean_compactness=low']\n",
      "support=53 / 357 (0.15)  pattern=['texture_error=high']\n",
      "support=52 / 357 (0.15)  pattern=['worst_concavity=low']\n",
      "support=51 / 357 (0.14)  pattern=['mean_perimeter=low']\n",
      "support=50 / 357 (0.14)  pattern=['worst_symmetry=low']\n",
      "support=45 / 357 (0.13)  pattern=['worst_fractal_dimension=low']\n",
      "support=45 / 357 (0.13)  pattern=['smoothness_error=high']\n",
      "support=43 / 357 (0.12)  pattern=['smoothness_error=low']\n",
      "support=41 / 357 (0.11)  pattern=['worst_texture=low', 'mean_texture=low']\n",
      "support=41 / 357 (0.11)  pattern=['symmetry_error=low']\n",
      "support=39 / 357 (0.11)  pattern=['mean_fractal_dimension=low']\n"
     ]
    }
   ],
   "source": [
    "def mine_patterns(sequences, min_support_ratio=0.1, max_pattern_length=3, top_n=20):\n",
    "    \"\"\"\n",
    "    Mine frequent sequential patterns from 'sequences' using PrefixSpan.\n",
    "\n",
    "    sequences: list of sequences, where each sequence is a list of strings.\n",
    "               Example: [\n",
    "                   'worst_concavity=high|worst_compactness=high',\n",
    "                   'radius_mean=high', ...\n",
    "               ]\n",
    "    min_support_ratio: minimum fraction of patients that must contain the pattern.\n",
    "    max_pattern_length: only keep patterns up to this length for interpretability.\n",
    "    top_n: return the top_n most supported patterns.\n",
    "\n",
    "    This function wraps the PrefixSpan API from the open-source `prefixspan` package.\n",
    "    \"\"\"\n",
    "    n_seq = len(sequences)\n",
    "    min_support = max(1, int(np.ceil(min_support_ratio * n_seq)))\n",
    "\n",
    "    ps = PrefixSpan(sequences)\n",
    "\n",
    "    # prefixspan.PrefixSpan.frequent(min_support) returns a list of tuples:\n",
    "    #   (support_count, pattern_sequence)\n",
    "    # where pattern_sequence is also a list of strings like the ones in our sequences.\n",
    "    raw_patterns = ps.frequent(min_support)\n",
    "\n",
    "    # filter by length so we don't get huge unreadable patterns\n",
    "    filtered = [\n",
    "        (supp, pat) for supp, pat in raw_patterns if len(pat) <= max_pattern_length\n",
    "    ]\n",
    "\n",
    "    # sort patterns by support desc (and longer patterns slightly later in tie-break)\n",
    "    filtered.sort(key=lambda x: (x[0], len(x[1])), reverse=True)\n",
    "\n",
    "    return filtered[:top_n]\n",
    "\n",
    "\n",
    "patterns_M = mine_patterns(\n",
    "    seqs_M_collapsed, min_support_ratio=0.1, max_pattern_length=3, top_n=20\n",
    ")\n",
    "patterns_B = mine_patterns(\n",
    "    seqs_B_collapsed, min_support_ratio=0.1, max_pattern_length=3, top_n=20\n",
    ")\n",
    "\n",
    "print(\"Top malignant patterns:\")\n",
    "for supp, pat in patterns_M:\n",
    "    print(\n",
    "        f\"support={supp} / {len(seqs_M_collapsed)} \"\n",
    "        f\"({supp / len(seqs_M_collapsed):.2f})  pattern={pat}\"\n",
    "    )\n",
    "\n",
    "print(\"\\nTop benign patterns:\")\n",
    "for supp, pat in patterns_B:\n",
    "    print(\n",
    "        f\"support={supp} / {len(seqs_B_collapsed)} \"\n",
    "        f\"({supp / len(seqs_B_collapsed):.2f})  pattern={pat}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f648608",
   "metadata": {},
   "source": [
    "### 5b. Mine Sequential Patterns with GSP Algorithm\n",
    "\n",
    "**GSP (Generalized Sequential Pattern)** is another classic sequential pattern mining algorithm that:\n",
    "- Uses an Apriori-like approach\n",
    "- Generates candidate sequences\n",
    "- Makes multiple passes over the data\n",
    "- Has explicit support for time constraints and sliding windows\n",
    "\n",
    "We'll implement GSP as an alternative to PrefixSpan for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1d10d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top malignant patterns (GSP):\n",
      "support=60 / 212 (0.28)  pattern=['mean_radius=high']\n",
      "support=60 / 212 (0.28)  pattern=['mean_radius=high', 'mean_radius=high']\n",
      "support=49 / 212 (0.23)  pattern=['worst_radius=high']\n",
      "support=49 / 212 (0.23)  pattern=['worst_radius=high', 'worst_radius=high']\n",
      "support=47 / 212 (0.22)  pattern=['mean_area=high']\n",
      "support=47 / 212 (0.22)  pattern=['mean_area=high', 'mean_area=high']\n",
      "support=45 / 212 (0.21)  pattern=['worst_compactness=high']\n",
      "support=45 / 212 (0.21)  pattern=['worst_compactness=high', 'worst_compactness=high']\n",
      "support=43 / 212 (0.20)  pattern=['mean_perimeter=high']\n",
      "support=43 / 212 (0.20)  pattern=['mean_perimeter=high', 'mean_perimeter=high']\n",
      "\n",
      "Top benign patterns (GSP):\n",
      "support=91 / 357 (0.25)  pattern=['worst_texture=low']\n",
      "support=91 / 357 (0.25)  pattern=['worst_texture=low', 'worst_texture=low']\n",
      "support=84 / 357 (0.24)  pattern=['worst_smoothness=low']\n",
      "support=84 / 357 (0.24)  pattern=['mean_texture=low']\n",
      "support=84 / 357 (0.24)  pattern=['worst_smoothness=low', 'worst_smoothness=low']\n",
      "support=84 / 357 (0.24)  pattern=['mean_texture=low', 'mean_texture=low']\n",
      "support=81 / 357 (0.23)  pattern=['mean_smoothness=low']\n",
      "support=81 / 357 (0.23)  pattern=['mean_smoothness=low', 'mean_smoothness=low']\n",
      "support=78 / 357 (0.22)  pattern=['mean_symmetry=low']\n",
      "support=78 / 357 (0.22)  pattern=['mean_symmetry=low', 'mean_symmetry=low']\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def generate_candidates(prev_sequences, k):\n",
    "    \"\"\"Generate length-k candidate sequences from length-(k-1) frequent sequences\"\"\"\n",
    "    candidates = set()\n",
    "    for seq1 in prev_sequences:\n",
    "        for seq2 in prev_sequences:\n",
    "            # Join if first k-2 elements match\n",
    "            if seq1[:-1] == seq2[1:]:\n",
    "                candidates.add(seq1 + (seq2[-1],))\n",
    "    return candidates\n",
    "\n",
    "\n",
    "def gsp_mine(sequences, min_support_ratio=0.1, max_length=3):\n",
    "    \"\"\"\n",
    "    Mine sequential patterns using GSP algorithm\n",
    "\n",
    "    Parameters:\n",
    "    sequences: list of sequences (same format as used for PrefixSpan)\n",
    "    min_support_ratio: minimum support threshold as a fraction\n",
    "    max_length: maximum pattern length to mine\n",
    "    \"\"\"\n",
    "    n_sequences = len(sequences)\n",
    "    min_support = max(1, int(np.ceil(min_support_ratio * n_sequences)))\n",
    "\n",
    "    # Find frequent 1-sequences\n",
    "    item_counts = defaultdict(int)\n",
    "    for seq in sequences:\n",
    "        for item in set(seq):  # Count unique items per sequence\n",
    "            item_counts[item] += 1\n",
    "\n",
    "    L1 = {(item,) for item, count in item_counts.items() if count >= min_support}\n",
    "\n",
    "    current_L = L1\n",
    "    all_patterns = []\n",
    "    k = 1\n",
    "\n",
    "    while current_L and k < max_length:\n",
    "        # Add current frequent sequences to results\n",
    "        for pattern in current_L:\n",
    "            support = sum(1 for seq in sequences if all(p in seq for p in pattern))\n",
    "            all_patterns.append((support, list(pattern)))\n",
    "\n",
    "        # Generate candidates\n",
    "        candidates = generate_candidates(current_L, k + 1)\n",
    "\n",
    "        # Count support\n",
    "        current_L = set()\n",
    "        for cand in candidates:\n",
    "            support = sum(1 for seq in sequences if all(p in seq for p in cand))\n",
    "            if support >= min_support:\n",
    "                current_L.add(cand)\n",
    "        k += 1\n",
    "\n",
    "    # Sort by support\n",
    "    all_patterns.sort(key=lambda x: (-x[0], len(x[1])))\n",
    "    return all_patterns\n",
    "\n",
    "\n",
    "# Run GSP on malignant and benign sequences\n",
    "patterns_M_gsp = gsp_mine(seqs_M_collapsed, min_support_ratio=0.1, max_length=3)\n",
    "patterns_B_gsp = gsp_mine(seqs_B_collapsed, min_support_ratio=0.1, max_length=3)\n",
    "\n",
    "print(\"Top malignant patterns (GSP):\")\n",
    "for supp, pat in patterns_M_gsp[:10]:\n",
    "    print(\n",
    "        f\"support={supp} / {len(seqs_M_collapsed)} ({supp / len(seqs_M_collapsed):.2f})  pattern={pat}\"\n",
    "    )\n",
    "\n",
    "print(\"\\nTop benign patterns (GSP):\")\n",
    "for supp, pat in patterns_B_gsp[:10]:\n",
    "    print(\n",
    "        f\"support={supp} / {len(seqs_B_collapsed)} ({supp / len(seqs_B_collapsed):.2f})  pattern={pat}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f34f8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison for Malignant patterns:\n",
      "\n",
      "Patterns found by both algorithms:\n",
      "('mean_radius=high',)\n",
      "('worst_concavity=high',)\n",
      "('mean_concavity=high',)\n",
      "('worst_fractal_dimension=high',)\n",
      "('worst_texture=high',)\n",
      "('radius_error=high',)\n",
      "('perimeter_error=high',)\n",
      "('worst_perimeter=high',)\n",
      "('mean_concave_points=high',)\n",
      "('mean_fractal_dimension=low',)\n",
      "('worst_radius=high',)\n",
      "('mean_texture=high',)\n",
      "('worst_compactness=high',)\n",
      "('mean_area=high',)\n",
      "('worst_smoothness=high',)\n",
      "('mean_perimeter=high',)\n",
      "('worst_concave_points=high',)\n",
      "('worst_symmetry=high',)\n",
      "('mean_radius=high', 'mean_perimeter=high')\n",
      "('worst_area=high',)\n",
      "\n",
      "Unique to PrefixSpan (0):\n",
      "\n",
      "Unique to GSP (48):\n",
      "('worst_area=high', 'worst_area=high')\n",
      "('worst_perimeter=high', 'worst_perimeter=high')\n",
      "('mean_perimeter=high', 'mean_perimeter=high')\n",
      "('worst_perimeter=high', 'worst_radius=high')\n",
      "('worst_compactness=high', 'worst_concavity=high')\n",
      "('area_error=high',)\n",
      "('worst_compactness=high', 'worst_fractal_dimension=high')\n",
      "('mean_compactness=high',)\n",
      "('worst_smoothness=high', 'worst_smoothness=high')\n",
      "('worst_radius=high', 'worst_area=high')\n",
      "('radius_error=high', 'radius_error=high')\n",
      "('mean_radius=high', 'mean_radius=high')\n",
      "('area_error=high', 'area_error=high')\n",
      "('radius_error=high', 'perimeter_error=high')\n",
      "('mean_perimeter=high', 'mean_radius=high')\n",
      "('mean_texture=high', 'worst_texture=high')\n",
      "('mean_area=high', 'worst_radius=high')\n",
      "('worst_radius=high', 'mean_radius=high')\n",
      "('mean_concave_points=high', 'mean_concave_points=high')\n",
      "('mean_smoothness=high',)\n",
      "('worst_concavity=high', 'worst_concavity=high')\n",
      "('worst_area=high', 'worst_perimeter=high')\n",
      "('worst_compactness=high', 'worst_compactness=high')\n",
      "('mean_area=high', 'mean_area=high')\n",
      "('worst_perimeter=high', 'worst_area=high')\n",
      "('worst_area=high', 'worst_radius=high')\n",
      "('worst_texture=high', 'worst_texture=high')\n",
      "('mean_radius=high', 'worst_radius=high')\n",
      "('perimeter_error=high', 'radius_error=high')\n",
      "('mean_texture=high', 'mean_texture=high')\n",
      "('worst_fractal_dimension=high', 'worst_fractal_dimension=high')\n",
      "('mean_area=high', 'mean_perimeter=high')\n",
      "('worst_radius=high', 'worst_perimeter=high')\n",
      "('mean_radius=high', 'mean_area=high')\n",
      "('perimeter_error=high', 'perimeter_error=high')\n",
      "('mean_fractal_dimension=low', 'mean_fractal_dimension=low')\n",
      "('worst_radius=high', 'worst_radius=high')\n",
      "('worst_symmetry=high', 'worst_symmetry=high')\n",
      "('mean_concavity=high', 'mean_concavity=high')\n",
      "('mean_smoothness=high', 'mean_smoothness=high')\n",
      "('mean_compactness=high', 'mean_compactness=high')\n",
      "('worst_texture=high', 'mean_texture=high')\n",
      "('mean_perimeter=high', 'mean_area=high')\n",
      "('worst_concavity=high', 'worst_compactness=high')\n",
      "('worst_concave_points=high', 'worst_concave_points=high')\n",
      "('worst_radius=high', 'mean_area=high')\n",
      "('worst_fractal_dimension=high', 'worst_compactness=high')\n",
      "('mean_area=high', 'mean_radius=high')\n",
      "\n",
      "Comparison for Benign patterns:\n",
      "\n",
      "Patterns found by both algorithms:\n",
      "('mean_radius=low',)\n",
      "('worst_smoothness=low',)\n",
      "('texture_error=low',)\n",
      "('worst_concavity=low',)\n",
      "('mean_perimeter=low',)\n",
      "('mean_symmetry=low',)\n",
      "('worst_texture=low', 'mean_texture=low')\n",
      "('worst_concave_points=low',)\n",
      "('mean_fractal_dimension=low',)\n",
      "('worst_texture=low',)\n",
      "('smoothness_error=low',)\n",
      "('texture_error=high',)\n",
      "('smoothness_error=high',)\n",
      "('mean_compactness=low',)\n",
      "('worst_fractal_dimension=low',)\n",
      "('mean_smoothness=low',)\n",
      "('concave_points_error=low',)\n",
      "('symmetry_error=low',)\n",
      "('worst_symmetry=low',)\n",
      "('mean_texture=low',)\n",
      "\n",
      "Unique to PrefixSpan (0):\n",
      "\n",
      "Unique to GSP (38):\n",
      "('worst_concave_points=low', 'worst_concave_points=low')\n",
      "('worst_smoothness=low', 'mean_smoothness=low')\n",
      "('mean_texture=low', 'texture_error=low')\n",
      "('mean_symmetry=low', 'mean_symmetry=low')\n",
      "('mean_smoothness=low', 'mean_smoothness=low')\n",
      "('concave_points_error=low', 'concave_points_error=low')\n",
      "('worst_symmetry=low', 'worst_symmetry=low')\n",
      "('mean_fractal_dimension=high', 'mean_fractal_dimension=high')\n",
      "('mean_radius=low', 'mean_radius=low')\n",
      "('symmetry_error=high', 'symmetry_error=high')\n",
      "('worst_smoothness=low', 'worst_smoothness=low')\n",
      "('mean_texture=low', 'worst_texture=low')\n",
      "('mean_smoothness=low', 'worst_smoothness=low')\n",
      "('mean_radius=low', 'mean_perimeter=low')\n",
      "('mean_smoothness=high',)\n",
      "('mean_fractal_dimension=high',)\n",
      "('mean_perimeter=low', 'mean_radius=low')\n",
      "('texture_error=high', 'texture_error=high')\n",
      "('texture_error=low', 'mean_texture=low')\n",
      "('worst_texture=low', 'texture_error=low')\n",
      "('worst_concave_points=low', 'concave_points_error=low')\n",
      "('mean_symmetry=low', 'worst_symmetry=low')\n",
      "('worst_symmetry=low', 'mean_symmetry=low')\n",
      "('symmetry_error=low', 'symmetry_error=low')\n",
      "('concave_points_error=low', 'worst_concave_points=low')\n",
      "('mean_perimeter=low', 'mean_perimeter=low')\n",
      "('worst_concavity=low', 'worst_concavity=low')\n",
      "('texture_error=low', 'texture_error=low')\n",
      "('worst_fractal_dimension=low', 'worst_fractal_dimension=low')\n",
      "('mean_fractal_dimension=low', 'mean_fractal_dimension=low')\n",
      "('smoothness_error=high', 'smoothness_error=high')\n",
      "('mean_smoothness=high', 'mean_smoothness=high')\n",
      "('mean_compactness=low', 'mean_compactness=low')\n",
      "('worst_texture=low', 'worst_texture=low')\n",
      "('smoothness_error=low', 'smoothness_error=low')\n",
      "('mean_texture=low', 'mean_texture=low')\n",
      "('texture_error=low', 'worst_texture=low')\n",
      "('symmetry_error=high',)\n"
     ]
    }
   ],
   "source": [
    "def compare_algorithms(prefixspan_patterns, gsp_patterns, label):\n",
    "    \"\"\"Compare patterns found by PrefixSpan and GSP\"\"\"\n",
    "    print(f\"\\nComparison for {label} patterns:\")\n",
    "    print(\"\\nPatterns found by both algorithms:\")\n",
    "    prefix_set = {tuple(pat) for _, pat in prefixspan_patterns}\n",
    "    gsp_set = {tuple(pat) for _, pat in gsp_patterns}\n",
    "    common = prefix_set.intersection(gsp_set)\n",
    "    for pat in common:\n",
    "        print(pat)\n",
    "\n",
    "    print(f\"\\nUnique to PrefixSpan ({len(prefix_set - gsp_set)}):\")\n",
    "    for pat in prefix_set - gsp_set:\n",
    "        print(pat)\n",
    "\n",
    "    print(f\"\\nUnique to GSP ({len(gsp_set - prefix_set)}):\")\n",
    "    for pat in gsp_set - prefix_set:\n",
    "        print(pat)\n",
    "\n",
    "\n",
    "# Compare results\n",
    "compare_algorithms(patterns_M, patterns_M_gsp, \"Malignant\")\n",
    "compare_algorithms(patterns_B, patterns_B_gsp, \"Benign\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d6da72",
   "metadata": {},
   "source": [
    "### 6. Summarize Which Features Dominate Each Class\n",
    "\n",
    "The `patterns_M` output is still a bit raw. Now we extract which symbolic features (like `worst_concavity=high`) show up most often in high-support malignant patterns vs benign patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075cd772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most characteristic items for Malignant (weighted):\n",
      "[('mean_radius=high', 90), ('mean_perimeter=high', 73), ('worst_radius=high', 49), ('mean_area=high', 47), ('worst_compactness=high', 45), ('worst_fractal_dimension=high', 42), ('worst_texture=high', 41), ('worst_perimeter=high', 40), ('mean_concave_points=high', 39), ('worst_concavity=high', 39)]\n",
      "\n",
      "Most characteristic items for Benign (weighted):\n",
      "[('worst_texture=low', 132), ('mean_texture=low', 125), ('worst_smoothness=low', 84), ('mean_smoothness=low', 81), ('mean_symmetry=low', 78), ('worst_concave_points=low', 73), ('concave_points_error=low', 68), ('texture_error=low', 66), ('mean_radius=low', 60), ('mean_compactness=low', 58)]\n"
     ]
    }
   ],
   "source": [
    "def summarize_top_attributes(patterns, top_k_attrs=10):\n",
    "    \"\"\"\n",
    "    patterns: list of (support, pattern)\n",
    "    pattern is a list of steps, where each step is now a *string*.\n",
    "    Each step may look like:\n",
    "        'featA=high|featB=high'\n",
    "    We'll split by \"|\" to count features individually.\n",
    "    \"\"\"\n",
    "    attr_counter = Counter()\n",
    "    for supp, pat in patterns:\n",
    "        for step in pat:\n",
    "            for atom in step.split(\"|\"):  # separate 'feat1=high|feat2=high'\n",
    "                attr_counter[atom] += supp  # weight by pattern support\n",
    "    return attr_counter.most_common(top_k_attrs)\n",
    "\n",
    "\n",
    "print(\"Most characteristic items for Malignant (weighted):\")\n",
    "print(summarize_top_attributes(patterns_M))\n",
    "\n",
    "print(\"\\nMost characteristic items for Benign (weighted):\")\n",
    "print(summarize_top_attributes(patterns_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff40b599",
   "metadata": {},
   "source": [
    "### 7. Sensitivity Check Across Binning Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed776eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malignant patterns (quantile binning):\n",
      "60 ['mean_radius=high']\n",
      "49 ['worst_radius=high']\n",
      "47 ['mean_area=high']\n",
      "45 ['worst_compactness=high']\n",
      "43 ['mean_perimeter=high']\n",
      "\n",
      "Malignant patterns (uniform binning):\n",
      "50 ['mean radius=mid']\n",
      "40 ['mean area=mid']\n",
      "38 ['worst radius=mid']\n",
      "35 ['worst compactness=mid']\n",
      "35 ['mean perimeter=mid']\n",
      "\n",
      "Benign patterns (quantile binning):\n",
      "91 ['worst_texture=low']\n",
      "84 ['mean_texture=low']\n",
      "84 ['worst_smoothness=low']\n",
      "81 ['mean_smoothness=low']\n",
      "78 ['mean_symmetry=low']\n",
      "\n",
      "Benign patterns (uniform binning):\n",
      "91 ['worst texture=low']\n",
      "84 ['mean texture=low']\n",
      "84 ['worst smoothness=low']\n",
      "81 ['mean smoothness=low']\n",
      "79 ['texture error=low']\n"
     ]
    }
   ],
   "source": [
    "def rebuild_sequences_from_disc(disc_df, k=5):\n",
    "    \"\"\"\n",
    "    Re-run the sequence construction using a different discretized dataframe\n",
    "    (e.g. disc_uniform instead of disc_quantile).\n",
    "    \"\"\"\n",
    "    seqs_tmp = []\n",
    "    for idx in X.index:\n",
    "        s = build_patient_sequence(idx, X_scaled_df, disc_df, k=k, tie_eps=1e-6)\n",
    "        seqs_tmp.append(s)\n",
    "    return seqs_tmp\n",
    "\n",
    "\n",
    "# 1. sequences using UNIFORM instead of QUANTILE\n",
    "seqs_all_uniform_raw = rebuild_sequences_from_disc(disc_uniform, k=5)\n",
    "\n",
    "# 2. collapse for PrefixSpan\n",
    "seqs_all_uniform_collapsed = [\n",
    "    collapse_itemsets_for_prefixspan(s) for s in seqs_all_uniform_raw\n",
    "]\n",
    "\n",
    "# 3. split by label again\n",
    "seqs_M_uniform = [\n",
    "    s\n",
    "    for s, lab in zip(seqs_all_uniform_collapsed, labels_all, strict=False)\n",
    "    if lab == \"M\"\n",
    "]\n",
    "seqs_B_uniform = [\n",
    "    s\n",
    "    for s, lab in zip(seqs_all_uniform_collapsed, labels_all, strict=False)\n",
    "    if lab == \"B\"\n",
    "]\n",
    "\n",
    "# 4. mine again\n",
    "patterns_M_uniform = mine_patterns(\n",
    "    seqs_M_uniform, min_support_ratio=0.1, max_pattern_length=3, top_n=10\n",
    ")\n",
    "patterns_B_uniform = mine_patterns(\n",
    "    seqs_B_uniform, min_support_ratio=0.1, max_pattern_length=3, top_n=10\n",
    ")\n",
    "\n",
    "print(\"Malignant patterns (quantile binning):\")\n",
    "for supp, pat in patterns_M[:5]:\n",
    "    print(supp, pat)\n",
    "\n",
    "print(\"\\nMalignant patterns (uniform binning):\")\n",
    "for supp, pat in patterns_M_uniform[:5]:\n",
    "    print(supp, pat)\n",
    "\n",
    "print(\"\\nBenign patterns (quantile binning):\")\n",
    "for supp, pat in patterns_B[:5]:\n",
    "    print(supp, pat)\n",
    "\n",
    "print(\"\\nBenign patterns (uniform binning):\")\n",
    "for supp, pat in patterns_B_uniform[:5]:\n",
    "    print(supp, pat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sc4020",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
